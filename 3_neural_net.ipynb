{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. 퍼셉트론에서 신경망으로\n",
    "2. 활성화 함수\n",
    "3. 다차원배열 계산\n",
    "4. 3층 신경망 구현\n",
    "5. 출력층 설계"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 퍼셉트론에서 신경망으로\n",
    "\n",
    "퍼셉트론은 입력 $x_i$, 가중치 $w_i$, 편향 $b$, 활성화함수 $h$에 대해 다음의 y를 출력한다.  \n",
    "$ y = h(b \\, + \\, \\sum x_iw_i) $  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 활성화 함수 종류\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sigmoid function\n",
    "$h(x) = 1 / (1 + e^{-x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 계단 함수\n",
    "$\n",
    "h(x) = \n",
    "\\begin{cases}\n",
    "1, \\, if \\, x > 0 \\\\\n",
    "0, \\, if \\, x \\leq 0\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stair(x:np.array):\n",
    "    y = x > 0\n",
    "    return y.astype(np.int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 왜 비선형 함수를 사용해야하는가?\n",
    "\n",
    "선형함수를 활성화함수로 사용할 경우, 입력층의 값에 가충치를 곱하는것과 같다. 즉, 다층 신경망의 의미가 없다.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ReLU 함수\n",
    "$\n",
    "h(x) = \n",
    "\\begin{cases}\n",
    "x, \\, if \\, x > 0 \\\\\n",
    "0, \\, if \\, x \\leq 0\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def ReLU(x:np.array):\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 다차원 배열의 연산\n",
    "![image.png](img/1.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 Y가 갖는값은 다음과 같다. [ 5 11 17]\n"
     ]
    }
   ],
   "source": [
    "def matrix_multi():\n",
    "    x = np.array([1, 2])\n",
    "    w = np.array([[1, 3, 5], [2, 4, 6]])\n",
    "    y = x.dot(w) # 행렬곱\n",
    "    return y\n",
    "\n",
    "print('각 Y가 갖는값은 다음과 같다.', matrix_multi())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 3층 신경망 구현하기\n",
    "![구현모습](img/2.PNG)  \n",
    "각 층에 적용되는 가중치를 각각 행렬로.  \n",
    "각 층을 각각 행렬로.  \n",
    "\n",
    "앞 층의 값과 가중치를 이용하여 forward propagation을 적용한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57855079 0.66736228]\n"
     ]
    }
   ],
   "source": [
    "#i행 j열의 가중치: i번째 노드가 j번째 노드에게 출력할때 적용되는 가중치 \n",
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([\n",
    "        [0.1, 0.3, 0.5],\n",
    "        [0.2, 0.4, 0.6]\n",
    "    ])\n",
    "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
    "    network['W2'] = np.array([\n",
    "        [0.1, 0.4],\n",
    "        [0.2, 0.5], \n",
    "        [0.3, 0.6]\n",
    "    ])\n",
    "    network['b2'] = np.array([0.1, 0.2])\n",
    "    network['W3'] = np.array([\n",
    "        [0.1, 0.3],\n",
    "        [0.2, 0.4]\n",
    "    ])\n",
    "    network['b3'] = np.array([0.1, 0.2])\n",
    "    \n",
    "    return network\n",
    "    \n",
    "def forward(network, x):\n",
    "    # 각 층을 구할때 가중치 적용해 구하는..\n",
    "    l0 = x\n",
    "    l1 = np.dot(l0, network['W1']) + network['b1']\n",
    "    l1 = sigmoid(l1)\n",
    "    \n",
    "    l2 = np.dot(l1, network['W2']) + network['b2']\n",
    "    l2 = sigmoid(l2)\n",
    "    \n",
    "    l3 = np.dot(l2, network['W3']) + network['b3']\n",
    "    l3 = sigmoid(l3)\n",
    "    \n",
    "    return l3\n",
    "\n",
    "x = np.array([1.0, 0.5])\n",
    "y = forward(init_network(), x)\n",
    "print(y)   \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc3d4a3c7dbff72f14f38a3086f756d1b4fd12ee242fef247cc57636fbb2858b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
